{"cells":[{"cell_type":"markdown","source":["### Przetwarzanie danych z sondaży aerologicznych\n\nŹródło danych: http://weather.uwyo.edu/upperair/sounding.html\n\nDokonano ekstrakcji danych pomiarowych dla zakresu dat: 2015.06.01 - 2017.05.31\n\nIlość rekordów wynosi: 136 478\n\nKażdy wiersz danych składa się z 6 pól:\n* data i godzina pomiaru\n* ciśnienie\n* wysokość balonu\n* temperatura powietrza\n* temperatura punktu rosy\n* wilgotność względna"],"metadata":{}},{"cell_type":"markdown","source":["###### Załadowanie zewnętrznych danych"],"metadata":{}},{"cell_type":"code","source":["lines = sc.textFile(\"/FileStore/tables/5b5j3tjn1496938672882/\")\nparts = lines.map(lambda l: l.split(\";\"))\n# Each line is converted to a tuple.\nmeasures = parts.map(lambda p: (p[0], p[1], p[2], p[3], p[4], p[5]))\n\nschema = StructType(\n  [\n    StructField('datetime', StringType(), False),\n    StructField('pressure', FloatType(), False),\n    StructField('height', IntegerType(), False),\n    StructField('temp', FloatType(), False),\n    StructField('dewpoint', FloatType(), False),\n    StructField('humidity', FloatType(), False)\n  ]\n)\n\n# Apply the schema to the RDD.\nschemaMeasures = spark.createDataFrame(measures, schema)\n\nprint('Current number of partitions: ' + str(measures.getNumPartitions()))\nprint('Number of rows: ' + str(measures.count()))"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["print(measures.collect()[0])\ndf = schemaMeasures.filter(schemaMeasures.height > 1000)\naverageCount = schemaMeasures.groupBy().mean()\nrdd = df.rdd.map(list)\nprint(measures)\nprint(averageCount.select('avg(pressure)').collect())\n\n\n\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["###### Wykonanie agregacji na RDD"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["###### Przekształcenie RDD do DataFrame"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["###### Wykonanie agregacji na DF (DSL i SQL)"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["###### Wizualizacja danych"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["###### Wykorzystanie dowolnego algorytmu z Spark MLlib"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"meteo","notebookId":3720619873347694},"nbformat":4,"nbformat_minor":0}
